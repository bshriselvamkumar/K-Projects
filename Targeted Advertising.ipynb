{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5ccf3f-8b4d-45f5-ba92-8d66bb282c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset saved as 'targeted_advertising_data.csv'.\n",
      "   user_id  age  gender purchasing_pattern  online_behavior_score  ad_clicks\n",
      "0        0   56    Male             Medium               0.043978          5\n",
      "1        1   46    Male                Low               0.820686          0\n",
      "2        2   32    Male             Medium               0.199031          5\n",
      "3        3   60  Female                Low               0.531554          4\n",
      "4        4   25    Male                Low               0.248763          1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   user_id                20000 non-null  int64  \n",
      " 1   age                    20000 non-null  int64  \n",
      " 2   gender                 20000 non-null  object \n",
      " 3   purchasing_pattern     20000 non-null  object \n",
      " 4   online_behavior_score  20000 non-null  float64\n",
      " 5   ad_clicks              20000 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 937.6+ KB\n",
      "None\n",
      "            user_id           age  online_behavior_score     ad_clicks\n",
      "count  20000.000000  20000.000000           20000.000000  20000.000000\n",
      "mean    9999.500000     40.900900               0.503091      4.523150\n",
      "std     5773.647028     13.488075               0.288615      2.882565\n",
      "min        0.000000     18.000000               0.000093      0.000000\n",
      "25%     4999.750000     29.000000               0.254486      2.000000\n",
      "50%     9999.500000     41.000000               0.502549      5.000000\n",
      "75%    14999.250000     53.000000               0.755262      7.000000\n",
      "max    19999.000000     64.000000               0.999862      9.000000\n",
      "--- Tuning Logistic Regression ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       405\n",
      "           1       0.81      0.94      0.88       400\n",
      "           2       0.80      0.57      0.66       442\n",
      "           3       0.44      0.64      0.52       390\n",
      "           4       0.43      0.28      0.34       401\n",
      "           5       0.49      0.34      0.40       437\n",
      "           6       0.32      0.41      0.36       419\n",
      "           7       0.51      0.44      0.47       419\n",
      "           8       0.64      0.58      0.61       397\n",
      "           9       0.74      0.99      0.84       398\n",
      "\n",
      "    accuracy                           0.61      4108\n",
      "   macro avg       0.62      0.62      0.61      4108\n",
      "weighted avg       0.62      0.61      0.61      4108\n",
      "\n",
      "Best AUC: 0.9253167641058827\n",
      "Best Model Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "\n",
      "\n",
      "--- Tuning Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       405\n",
      "           1       1.00      1.00      1.00       400\n",
      "           2       1.00      1.00      1.00       442\n",
      "           3       1.00      1.00      1.00       390\n",
      "           4       1.00      1.00      1.00       401\n",
      "           5       1.00      1.00      1.00       437\n",
      "           6       1.00      1.00      1.00       419\n",
      "           7       1.00      1.00      1.00       419\n",
      "           8       1.00      1.00      1.00       397\n",
      "           9       1.00      1.00      1.00       398\n",
      "\n",
      "    accuracy                           1.00      4108\n",
      "   macro avg       1.00      1.00      1.00      4108\n",
      "weighted avg       1.00      1.00      1.00      4108\n",
      "\n",
      "Best AUC: 1.0\n",
      "Best Model Parameters: {'max_depth': 10, 'n_estimators': 500}\n",
      "\n",
      "\n",
      "--- Tuning XGBoost ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       405\n",
      "           1       1.00      1.00      1.00       400\n",
      "           2       1.00      1.00      1.00       442\n",
      "           3       1.00      1.00      1.00       390\n",
      "           4       1.00      1.00      1.00       401\n",
      "           5       1.00      1.00      1.00       437\n",
      "           6       1.00      1.00      1.00       419\n",
      "           7       1.00      1.00      1.00       419\n",
      "           8       1.00      1.00      1.00       397\n",
      "           9       1.00      1.00      1.00       398\n",
      "\n",
      "    accuracy                           1.00      4108\n",
      "   macro avg       1.00      1.00      1.00      4108\n",
      "weighted avg       1.00      1.00      1.00      4108\n",
      "\n",
      "Best AUC: 1.0\n",
      "Best Model Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "\n",
      "Best model saved as 'best_ad_model.sav'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Step 1: Generate synthetic dataset\n",
    "np.random.seed(42)\n",
    "num_rows = 20000\n",
    "data = {\n",
    "    'user_id': range(num_rows),\n",
    "    'age': np.random.randint(18, 65, num_rows),\n",
    "    'gender': np.random.choice(['Male', 'Female'], num_rows),\n",
    "    'purchasing_pattern': np.random.choice(['High', 'Medium', 'Low'], num_rows),\n",
    "    'online_behavior_score': np.random.uniform(0, 1, num_rows),\n",
    "    'ad_clicks': np.random.randint(0, 10, num_rows)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('targeted_advertising_data.csv', index=False)\n",
    "print(\"Sample dataset saved as 'targeted_advertising_data.csv'.\")\n",
    "\n",
    "# Step 2: Load and explore the dataset\n",
    "df = pd.read_csv('targeted_advertising_data.csv')\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Step 3: Data preprocessing\n",
    "le = OneHotEncoder(drop='first')\n",
    "X_encoded = le.fit_transform(df[['gender', 'purchasing_pattern']])\n",
    "X = pd.concat([df.drop(['gender', 'purchasing_pattern'], axis=1), pd.DataFrame(X_encoded.toarray(), columns=le.get_feature_names_out())], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X[['age', 'online_behavior_score']] = scaler.fit_transform(X[['age', 'online_behavior_score']])\n",
    "y = df['ad_clicks']\n",
    "\n",
    "# Balance the dataset using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train and tune models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=100, multi_class='ovr'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'Logistic Regression': {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']},\n",
    "    'Random Forest': {'n_estimators': [100, 200, 500], 'max_depth': [10, 20, 30]},\n",
    "    'XGBoost': {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]}\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"--- Tuning {name} ---\")\n",
    "    grid_search = GridSearchCV(model, param_grid[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    auc_score = roc_auc_score(y_test, best_model.predict_proba(X_test), multi_class='ovr')\n",
    "    print(f\"Best AUC: {auc_score}\")\n",
    "    print(f\"Best Model Parameters: {grid_search.best_params_}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Save the best model (XGBoost assumed to be best)\n",
    "joblib.dump(best_model, 'best_ad_model.sav')\n",
    "print(\"Best model saved as 'best_ad_model.sav'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e35293-5ef1-491c-a817-302d8014ad46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dce92d-a8fd-4ae5-95f8-2288372bd1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03b4c9-f699-41f8-92be-5e4b643cc125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b79a580-53bc-44cd-8e99-473fb2727a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebe1af-281d-4848-9bc0-fc55b9a682ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef7e94-cc17-4179-b82f-19fb6827fb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ddeaa-6f2e-43b1-b4d6-7bbdb18dc47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
